# RunPod Serverless Dockerfile for Z-Image Text-to-Image Generation
FROM runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy project files
COPY requirements.txt .
COPY handler.py .

# Install Python dependencies with aggressive cleanup
RUN pip install --no-cache-dir -r requirements.txt \
    && pip cache purge \
    && rm -rf /tmp/* /var/tmp/* ~/.cache/*

# Pre-download the Z-Image model to cache it in the Docker image
# This prevents workers from downloading the model on every startup
RUN python3 -c "\
import torch; \
from diffusers import ZImagePipeline; \
print('Pre-downloading Z-Image-Turbo model...'); \
pipe = ZImagePipeline.from_pretrained('Tongyi-MAI/Z-Image-Turbo', torch_dtype=torch.bfloat16); \
print('Model cached successfully')" \
    && rm -rf /tmp/* /var/tmp/*

# Set Python path
ENV PYTHONPATH=/app:$PYTHONPATH

# Run the handler (model is already cached in the image)
CMD ["python", "-u", "handler.py"]
